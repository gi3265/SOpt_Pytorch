{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "subjective-falls",
   "metadata": {},
   "source": [
    "Lab-02 Linear regression\n",
    "학습목표\n",
    "\n",
    "선형회귀(Linear Regression)에 대해 알아본다.\n",
    "핵심키워드\n",
    "\n",
    "* 선형회귀(Linear Regression)\n",
    "* 평균 제곱 오차(Mean Squared Error)\n",
    "* 경사하강법(Gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "particular-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-workshop",
   "metadata": {},
   "source": [
    "## Data Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "constant-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 공부 시간\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 점수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-fourth",
   "metadata": {},
   "source": [
    "Weight와 bias를 0으로 초기화: 항상 처음에는 모델이 0을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "valuable-sitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros(1, requires_grad = True)  # requires_grad = True <- 학습할 것이라고 명시\n",
    "b = torch.zeros(1, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "embedded-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-prerequisite",
   "metadata": {},
   "source": [
    "## compute loss할 때의 loss함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "computational-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((hypothesis - y_train)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-respect",
   "metadata": {},
   "source": [
    "## Computed Loss를 활용해서 모델 개선시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bigger-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "associate-silly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SGI\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:132: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    }
   ],
   "source": [
    "# torch.optim 라이브러리 사용\n",
    "optimizer = optim.SGD([W, b], lr = 0.01)  # W,b는 학습할 텐서들. \n",
    "\n",
    "# optimizer을 통해 학습시킬 때 항상 붙어다니는 3줄\n",
    "optimizer.zero_grad()  # zero_grad()로 gradient 초기화\n",
    "loss.backward()  # backward()로 gradient 계산\n",
    "optimizer.step()  # step()으로 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-breed",
   "metadata": {},
   "source": [
    "## Full Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-wealth",
   "metadata": {},
   "source": [
    "한번만!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reasonable-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data 정의\n",
    "x_train = torch.FloatTensor([[1],[2],[3]]) # 공부 시간\n",
    "y_train = torch.FloatTensor([[2],[4],[6]]) # 점수\n",
    "# 초기 파라미터 정의(모델 초기화)\n",
    "W = torch.zeros(1, requires_grad = True)  # requires_grad = True <- 학습할 것이라고 명시\n",
    "b = torch.zeros(1, requires_grad = True)\n",
    "# Optimizer(파라미터 개선 규칙) 정의\n",
    "optimizer = optim.SGD([W, b], lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-lightning",
   "metadata": {},
   "source": [
    "반복!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "superb-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_nb = 1000\n",
    "for epoch in range(1, epochs_nb+1):\n",
    "    # loss 구하기: 예측 -> Loss(cost) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "    loss = torch.mean((hypothesis - y_train)**2)  # 텐서들이므로 x = [1,2,3], y = [1,2,3] 통째로 연산\n",
    "    \n",
    "    # 구해진 loss값과 optimizer을 토대로 파라미터 개선하기\n",
    "    optimizer.zero_grad() \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-pastor",
   "metadata": {},
   "source": [
    "W, b가 각각 최적의 수로 수렴함!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
